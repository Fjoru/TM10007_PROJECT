{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fjoru/TM10007_PROJECT/blob/Gonnie/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Prediction of tumor grade in brain cancer\n",
        "By Jessica Barends, Gonnie van Erp, Erik Kemper en Carlijn Oerlemans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xw_qQnScF4p",
        "colab_type": "code",
        "outputId": "c563bd68-2df5-4c97-a4e8-c06ee7cc8dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "# Run install for use in colab environment\n",
        "!pip install --upgrade pip\n",
        "!pip install -q --upgrade git+https://github.com/Fjoru/TM10007_PROJECT\n",
        "!pip install ipdb -q\n",
        "!pip install seaborn\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 1.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (46.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF9cuHLcdguY",
        "colab_type": "text"
      },
      "source": [
        "## Import section\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pgvYp3dGOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ipdb\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "# import tensorflow as tf\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ-dUjXUpFAG",
        "colab_type": "text"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyRkeYMXnkN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Replace(i):\n",
        "    if isinstance(i, int):\n",
        "          return i\n",
        "    try:\n",
        "        float(i)\n",
        "        return float(i)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def preprocessing_steps(X_design, Y_design, X_test, Y_test):\n",
        "    # training set\n",
        "    # remove strings from data\n",
        "    X_design = X_design.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_design.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_design.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # remove features with less than 60% values\n",
        "    X_design = X_design.dropna(thresh=round(X_design.shape[0]*0.6), axis='columns')\n",
        "\n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_design = X_design.join(Y_design)\n",
        "    # remove samples with not enough values\n",
        "    XY_design = XY_design.dropna(thresh=round(XY_design.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_design['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_design = XY_design[XY_design['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_data) and labels (Y_data)\n",
        "    X_design = XY_design.drop(columns=['label'])\n",
        "    Y_design = XY_design[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    imputer = IterativeImputer(sample_posterior=True, n_nearest_features=20, random_state=0)\n",
        "    X_design_imputed = imputer.fit_transform(X_design)\n",
        "\n",
        "    # normalization of values\n",
        "    scaler = RobustScaler()\n",
        "    X_design_scaled = scaler.fit_transform(X_design_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_design = pd.DataFrame(X_design_scaled, columns=X_design.columns, index=X_design.index)\n",
        "\n",
        "    ####### test set\n",
        "    # remove strings from data\n",
        "    X_test = X_test.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_test.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    \n",
        "    # remove the same features as the design set\n",
        "    features_design = X_design.columns\n",
        "    features_design = X_design.columns\n",
        "    \n",
        "    df_test = None\n",
        "    for feature in features_design:\n",
        "      df_test_single = pd.DataFrame(X_test[feature])\n",
        "      if df_test is None:\n",
        "        df_test = df_test_single\n",
        "      else:\n",
        "        df_test = df_test.join(df_test_single, how='outer')\n",
        "    \n",
        "    X_test = df_test\n",
        "    \n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_test = X_test.join(Y_test)\n",
        "    # remove samples with not enough values\n",
        "    XY_test = XY_test.dropna(thresh=round(XY_test.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_test['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_test = XY_test[XY_test['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_test) and labels (Y_test)\n",
        "    X_test = XY_test.drop(columns=['label'])\n",
        "    Y_test = XY_test[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    # normalization of values\n",
        "    X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    return X_design, Y_design, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBXawKAVfGD",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection and extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8o6DTQGVvjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_steps(X_design, Y_design):\n",
        "\n",
        "    impo_clf = ExtraTreesClassifier(n_estimators=50)\n",
        "    impo_clf = impo_clf.fit(X_data, Y_data)\n",
        "    impo_clf.feature_importances_\n",
        "\n",
        "    importances = impo_clf.feature_importances_\n",
        "    std = np.std([impo_clf.feature_importances_ for tree in impo_clf.estimators_], \n",
        "                 axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature importances\")\n",
        "    plt.bar(range(X_data.shape[1]), importances[indices],\n",
        "            color=\"r\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(X_data.shape[1]), indices)\n",
        "    plt.xlim([-1, X_data.shape[1]])\n",
        "    plt.show()\n",
        "\n",
        "    model = SelectFromModel(impo_clf, prefit=True)\n",
        "    X_data = model.transform(X_data)\n",
        "\n",
        "    return X_data, Y_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k75dmykgpM6y",
        "colab_type": "text"
      },
      "source": [
        "## Classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZrPWECtpRNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def classifiers (X_design, Y_design, X_test, Y_test):\n",
        " \n",
        " ## Example for Classifier hyperparameters selecting\n",
        "    clfs = {svm.SVC(propability=True): {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
        "            RandomForestClassifier(): {'n_estimators':range(1,400,5)}\n",
        "            }\n",
        "\n",
        "    for clf, parameters in clfs.items():\n",
        "        scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'f1-score': make_scorer(f1_score)}\n",
        "\n",
        "        random_search = model_selection.RandomizedSearchCV(clf, parameters, scoring=scoring, refit='AUC') ## hierin zit al de crossvalidatie, dus opnieuw een k-fold split hoeft niet #keuze om score voor alle classifiers gelijk te houden of per classifier te definieren\n",
        "        random_search.fit(X_design, Y_design)\n",
        "\n",
        "        # Get resulting classifier\n",
        "        clf_best = random_search.best_estimator_\n",
        "        print(f'Best classifier: parameters={clf_best.params}')\n",
        "        best_parameters.append(clf_best.params)   #per fold best classifier will be appended\n",
        "\n",
        "        # Test the classifier on the test data\n",
        "        # prob = clf_best.predict_proba(X_test)\n",
        "        # scores = prob[:, 1]\n",
        "\n",
        "      \t# Gettin accuracy, AUC and f1-score\n",
        "        #accuracy = accuracy_score(Y_test, scores)\n",
        "        #auc = metrics.roc_auc_score(Y_test, scores)\n",
        "        #f1 = f1_score(Y_test, scores)\n",
        "        #results.append({\n",
        "            #'accuracy': accuracy,\n",
        "            #'AUC': auc,\n",
        "            #'f1-score': f1,\n",
        "            #'kernel': clf_best.kernel,\n",
        "            #'set': test\n",
        "            #})\n",
        "\n",
        "        # Test the classifier on the training data\n",
        "        prob_testing = clf.predict_proba(X_design)\n",
        "        scores_training = prob_testing[:, 1]\n",
        "    \n",
        "        # Getting the accuracy, AUC and f1-score\n",
        "        accuracy = accuracy_score(Y_design, scores_training)\n",
        "        auc = roc_auc_score(Y_design, scores_training)\n",
        "        f1 = f1_score(Y_design, scores_training)\n",
        "        results.append({\n",
        "            'accuracy': accuracy,\n",
        "            'AUC': auc,\n",
        "            'f1-score': f1,\n",
        "            'clf': clf\n",
        "            'parameters': clf_best.param,\n",
        "            'set': training\n",
        "              })\n",
        "\n",
        "        # Create results dataframe and plot it\n",
        "        results = pd.DataFrame(results)\n",
        "        seaborn.boxplot(y='AUC', x='clf', data=results)\n",
        "        seaborn.boxplot(y='accuracy', x='clf', data=results)\n",
        "        seaborn.boxplot(y='f1-score', x='clf', data=results)\n",
        "\n",
        "        optimal_kernel = int(np.median(best_kernel))\n",
        "        print(f\"The optimal kernel={optimal_kernel}\")\n",
        "    \n",
        "       return results, optimal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCKzUBX7rpOj"
      },
      "source": [
        "## Run Pipeline\n",
        "\n",
        "run all predefined steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IYk4DjwcF48",
        "colab_type": "code",
        "outputId": "dd85a505-aa7d-4a6c-c0e8-09417ea56f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Data loading functions.\n",
        "from brats.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "# split labels and values\n",
        "data_X = data.drop(columns=['label'])\n",
        "data_Y = data[['label']]\n",
        "\n",
        "# data split index forming\n",
        "Test_split = model_selection.StratifiedKFold(n_splits=10)\n",
        "results = list()\n",
        "best_parameters = list()\n",
        "\n",
        "i = 0\n",
        "for design_index, test_index in Test_split.split(data_X, data_Y):\n",
        "    if i:\n",
        "      continue\n",
        "    X_design = data_X.iloc[design_index]\n",
        "    Y_design = data_Y.iloc[design_index]\n",
        "    \n",
        "    X_test = data_X.iloc[test_index]\n",
        "    Y_test = data_Y.iloc[test_index]\n",
        "\n",
        "    # run preprocessing step\n",
        "    X_design, Y_design, X_test, Y_test = preprocessing_steps(X_design, Y_design, X_test, Y_test)\n",
        "    print(X_design)\n",
        "    \n",
        "    #run feature selection and extraction\n",
        "    X_design, Y_design = feature_steps(X_design, Y_design)\n",
        "\n",
        "    i = 1\n",
        "    \n",
        "   \n",
        "\n",
        "# save data to csv for manual check\n",
        "#X_design.to_csv('data_X.csv')\n",
        "#Y_design.to_csv('data_Y.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n",
            "              VOLUME_ET  VOLUME_NET  ...  TGM_Cog_Z_1   TGM_T_1\n",
            "ID                                   ...                       \n",
            "TCGA-02-0064   0.306650   -0.149335  ...    -0.409811  0.412749\n",
            "TCGA-02-0068  -0.131777   -0.098523  ...    -0.254765 -0.182429\n",
            "TCGA-02-0069  -0.006484    0.912666  ...     0.284368  2.705034\n",
            "TCGA-02-0070  -0.274249   -0.314443  ...     0.839935 -0.449039\n",
            "TCGA-02-0075  -0.109278    0.247846  ...     0.451606 -0.017942\n",
            "...                 ...         ...  ...          ...       ...\n",
            "TCGA-HT-8018  -0.506682   -0.179239  ...    -0.849962 -0.833459\n",
            "TCGA-HT-8111  -0.512206   -0.381408  ...     1.026131 -0.804997\n",
            "TCGA-HT-8114  -0.282298    3.740634  ...     0.526592 -0.757509\n",
            "TCGA-HT-8563  -0.181188   -0.367314  ...    -0.466627 -0.801878\n",
            "TCGA-HT-A61A   0.757504    1.082333  ...    -0.592295  0.330073\n",
            "\n",
            "[150 rows x 698 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best classifier: kernel=rbf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ba4302003181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Test the classifier on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             raise NotFittedError(\"predict_proba is not available when fitted \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    465\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    466\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 698 should be equal to 182, the number of features at training time"
          ]
        }
      ]
    }
  ]
}