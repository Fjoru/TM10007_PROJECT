{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fjoru/TM10007_PROJECT/blob/Carlijn/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Prediction of tumor grade in brain cancer\n",
        "By Jessica Barends, Gonnie van Erp, Erik Kemper en Carlijn Oerlemans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xw_qQnScF4p",
        "colab_type": "code",
        "outputId": "5aa0738a-4959-4ade-fc3f-d3e6783ccb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run install for use in colab environment\n",
        "!pip install --upgrade pip\n",
        "!pip install -q --upgrade git+https://github.com/Fjoru/TM10007_PROJECT\n",
        "!pip install ipdb -q\n",
        "!pip install seaborn\n",
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.3)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF9cuHLcdguY",
        "colab_type": "text"
      },
      "source": [
        "## Import section\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pgvYp3dGOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ipdb\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Feature selection\n",
        "import umap\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Classifiers used in random search\n",
        "from sklearn import svm\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Evaluation metrics used\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ-dUjXUpFAG",
        "colab_type": "text"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyRkeYMXnkN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Replace(i):\n",
        "    if isinstance(i, int):\n",
        "          return i\n",
        "    try:\n",
        "        float(i)\n",
        "        return float(i)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def preprocessing_steps(X_design, Y_design, X_test, Y_test):\n",
        "    # training set\n",
        "    # remove strings from data\n",
        "    X_design = X_design.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_design.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_design.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # remove features with less than 60% values\n",
        "    X_design = X_design.dropna(thresh=round(X_design.shape[0]*0.6), axis='columns')\n",
        "\n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_design = X_design.join(Y_design)\n",
        "    # remove samples with not enough values\n",
        "    XY_design = XY_design.dropna(thresh=round(XY_design.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_design['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_design = XY_design[XY_design['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_data) and labels (Y_data)\n",
        "    X_design = XY_design.drop(columns=['label'])\n",
        "    Y_design = XY_design[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    imputer = IterativeImputer(sample_posterior=True, n_nearest_features=20, random_state=0)\n",
        "    X_design_imputed = imputer.fit_transform(X_design)\n",
        "\n",
        "    # normalization of values\n",
        "    scaler = RobustScaler()\n",
        "    X_design_scaled = scaler.fit_transform(X_design_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_design = pd.DataFrame(X_design_scaled, columns=X_design.columns, index=X_design.index)\n",
        "\n",
        "    ####### test set\n",
        "    # remove strings from data\n",
        "    X_test = X_test.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_test.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    \n",
        "    # remove the same features as the design set\n",
        "    features_design = X_design.columns\n",
        "    features_design = X_design.columns\n",
        "    \n",
        "    df_test = None\n",
        "    for feature in features_design:\n",
        "      df_test_single = pd.DataFrame(X_test[feature])\n",
        "      if df_test is None:\n",
        "        df_test = df_test_single\n",
        "      else:\n",
        "        df_test = df_test.join(df_test_single, how='outer')\n",
        "    \n",
        "    X_test = df_test\n",
        "    \n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_test = X_test.join(Y_test)\n",
        "    # remove samples with not enough values\n",
        "    XY_test = XY_test.dropna(thresh=round(XY_test.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_test['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_test = XY_test[XY_test['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_test) and labels (Y_test)\n",
        "    X_test = XY_test.drop(columns=['label'])\n",
        "    Y_test = XY_test[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    # normalization of values\n",
        "    X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    return X_design, Y_design, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBXawKAVfGD",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection and extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8o6DTQGVvjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def feature_steps(X_design, Y_design):\n",
        "    '''\n",
        "    Feature steps Hyperparameters:\n",
        "    Feature selection:\n",
        "    - estimator type\n",
        "      - optional kernel\n",
        "    - RFECV\n",
        "      - steps\n",
        "      - minimal numb of features\n",
        "      - CV type\n",
        "      - number of splits\n",
        "      - scoring method\n",
        "    Feature extraction:\n",
        "    - estimator type\n",
        "    - UMAP\n",
        "      - numb of resulting features\n",
        "      - numb of used neighbors\n",
        "      - type of distance calculation\n",
        "      - minimal distance\n",
        "    '''\n",
        "\n",
        "    # *Design set*\n",
        "    # Feature selection\n",
        "    \n",
        "    # Create SVC model\n",
        "    #svc = svm.SVC(kernel=\"linear\") \n",
        "  \n",
        "    # Create RFE object\n",
        "    #rfecv = RFECV(\n",
        "    #    estimator=svc, step=1, min_features_to_select=1, \n",
        "    #    cv=model_selection.StratifiedKFold(n_splits=6), # number of CV steps\n",
        "    #    scoring='roc_auc')                              # type of scoring\n",
        "\n",
        "    # Preform cross-validation     \n",
        "    #X_design = rfecv.fit_transform(X_design, Y_design)\n",
        "    \n",
        "    # Plot number of features VS. cross-validation scores\n",
        "    #plt.figure()\n",
        "    #plt.xlabel(\"Number of features selected\")\n",
        "    #plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "    #plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "    #plt.show()\n",
        "    \n",
        "    # Feature extraction\n",
        "    \n",
        "    # Create UMAP model\n",
        "    # Docs on umap: https://umap-learn.readthedocs.io/en/latest/index.html\n",
        "    Umapper = umap.UMAP(n_neighbors=15, n_components=2)\n",
        "\n",
        "    # Preform model fitting and transformation\n",
        "    X_design = Umapper.fit_transform(X_design)\n",
        "    X_design = pd.DataFrame(X_design, index=Y_design.index)\n",
        "\n",
        "    # *Test Set*\n",
        "    # Feature selection\n",
        "    #X_test = rfecv.transform(X_test)\n",
        "\n",
        "    # Feature extraction\n",
        "\n",
        "    # preform model transsformation\n",
        "    #X_test = Umapper.transform(X_test)\n",
        "    #X_test = pd.DataFrame(X_test, index=Y_test.index)\n",
        "\n",
        "    # Visualize Feature extraction\n",
        "    # make label set binary\n",
        "    Y_design_bin = Y_design.replace(['GBM', 'LGG'], [1, 0])\n",
        "\n",
        "    # combine data and labels\n",
        "    #df = pd.DataFrame(data=X_design, index=Y_design_bin.index)\n",
        "    #df = df.join(Y_design_bin)\n",
        "\n",
        "    # generate pairplot\n",
        "    #pp = sns.pairplot(df[:], hue='label', size=1.8, aspect=1.8, \n",
        "    #                  palette={0: \"#9966FF\", 1: \"#FFE888\"},\n",
        "    #                  plot_kws=dict(edgecolor=\"black\", linewidth=0.5))\n",
        "    #fig = pp.fig \n",
        "    #fig.subplots_adjust(top=0.93, wspace=0.3)\n",
        "    #t = fig.suptitle('Feature Attributes Pairwise Plots', fontsize=14)\n",
        "\n",
        "    return X_design, Y_design, Y_design_bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k75dmykgpM6y",
        "colab_type": "text"
      },
      "source": [
        "## Classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZrPWECtpRNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def classifiers (X_design, Y_design, X_test, Y_test):\n",
        "    global results\n",
        "    global best_parameters\n",
        "   \n",
        "    ## Example for Classifier hyperparameters selecting\n",
        "    clfs = {svm.SVC(probability=True): {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': range(1,5,1)},\n",
        "            RandomForestClassifier(): {'n_estimators':range(1,400,5)},\n",
        "            KNeighborsClassifier() : {'n_neighbors': range(1,100,2), 'weights': ['uniform', 'distance']},\n",
        "            LinearDiscriminantAnalysis():{}\n",
        "            }\n",
        "    names = ['SVC', 'RandomForest', 'KNN', 'LinearDiscriminant']\n",
        "    n = 0\n",
        "  \n",
        "    for clf, parameters in clfs.items():\n",
        "        scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'f1-score': make_scorer(f1_score)}\n",
        "\n",
        "        random_search = RandomizedSearchCV(clf, parameters, scoring=scoring, refit='AUC', cv=None) ## hierin zit al de crossvalidatie, dus opnieuw een k-fold split hoeft niet #keuze om score voor alle classifiers gelijk te houden of per classifier te definieren\n",
        "        random_search.fit(X_design, Y_design)\n",
        "\n",
        "        # Get resulting classifier\n",
        "        clf_best = random_search.best_estimator_\n",
        "        print(f'Best classifier: parameters={random_search.best_params_}')\n",
        "        best_parameters.append(random_search.best_params_)   #per fold best classifier will be appended\n",
        "        scores = random_search.best_score_\n",
        "        print(random_search.cv_results_)\n",
        "        print (scores)\n",
        "\n",
        "        if n == 0:\n",
        "          clf_name = names[0]\n",
        "        elif n % 4 == 1:\n",
        "          clf_name = names[1]\n",
        "        elif n % 4 == 2:\n",
        "          clf_name = names[2]\n",
        "        elif n % 4 == 3:\n",
        "          clf_name = names[3]\n",
        "        elif n % 4 == 0:\n",
        "          clf_name = names[0]\n",
        "        n += 1 \n",
        "    \n",
        "        # Getting the accuracy, AUC and f1-score\n",
        "        accuracy = random_search.cv_results_['mean_test_Accuracy'][random_search.best_index_]\n",
        "        auc = random_search.cv_results_['mean_test_AUC'][random_search.best_index_]\n",
        "        f1 = random_search.cv_results_['mean_test_f1-score'][random_search.best_index_]\n",
        "        mean_score = (accuracy + auc + f1)/3\n",
        "        results.append({\n",
        "            'accuracy': accuracy,\n",
        "            'AUC': auc,\n",
        "            'f1-score': f1,\n",
        "            'mean_score': mean_score,\n",
        "            'clf_name': clf_name,\n",
        "            'clf': clf_best, \n",
        "            'parameters': random_search.best_params_,\n",
        "            'set': 'validation'\n",
        "              })\n",
        "        \n",
        "    # Create results dataframe and plot it\n",
        "    results = pd.DataFrame(results)\n",
        "    print(results)\n",
        "    sns.boxplot(y='AUC', x='clf_name', data=results)\n",
        "    sns.boxplot(y='accuracy', x='clf_name', data=results)\n",
        "    sns.boxplot(y='f1-score', x='clf_name', data=results)\n",
        "\n",
        "    index_best_classifier = results[['mean_score']].idxmax() \n",
        "    print(f'index_best_classifier={index_best_classifier}')\n",
        "    best_classifier_name = results['clf_name'][index_best_classifier]\n",
        "    best_classifier_name = best_classifier_name.tolist()\n",
        "    best_classifier = results['clf'][index_best_classifier]   \n",
        "    best_classifier = best_classifier.tolist()\n",
        "    print(f'best_classifier={best_classifier}')\n",
        "\n",
        "    # Train best classifier on total testdata\n",
        "    classifier_optimized = best_classifier[0].fit(X_design,Y_design)\n",
        "    pred_train = classifier_optimized.predict(X_design)\n",
        "\n",
        "    #Gettin accuracy, AUC and f1-score\n",
        "    accuracy_train = accuracy_score(Y_design, pred_train)\n",
        "    auc_train = roc_auc_score(Y_design, pred_train)\n",
        "    f1_train = f1_score(Y_design, pred_train)\n",
        "    results_outer.append({\n",
        "        'accuracy': accuracy_train,\n",
        "        'AUC': auc_train,\n",
        "        'f1-score': f1_train,\n",
        "        'clf': best_classifier[0],\n",
        "        'clf_name': best_classifier_name[0],\n",
        "        'set': 'training'\n",
        "        })\n",
        "    \n",
        "    #Test the classifier on the test data\n",
        "    pred_test = classifier_optimized.predict(X_test)\n",
        "\n",
        "    #Gettin accuracy, AUC and f1-score\n",
        "    accuracy_test = accuracy_score(Y_test, pred_test)\n",
        "    auc_test = roc_auc_score(Y_test, pred_test)\n",
        "    f1_test = f1_score(Y_test, pred_test)\n",
        "    results_outer.append({\n",
        "        'accuracy': accuracy_test,\n",
        "        'AUC': auc_test,\n",
        "        'f1-score': f1_test,\n",
        "        'clf': best_classifier[0],\n",
        "        'clf_name': best_classifier_name[0],\n",
        "        'set': 'testing'\n",
        "        })\n",
        "\n",
        "    \n",
        "    return results, results_outer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qG16XWa_tpRl"
      },
      "source": [
        "## Learning curves\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CubkdxgytxLK",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                         n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
        "\n",
        "  axes.set_title(title)\n",
        "  if ylim is not None:\n",
        "    axes.set_ylim(*ylim)\n",
        "  axes.set_xlabel(\"Training examples\")\n",
        "  axes.set_ylabel(\"Score\")\n",
        "\n",
        "  train_sizes, train_scores, test_scores= learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                                                       train_sizes=train_sizes)\n",
        "  train_scores_mean = np.mean(train_scores, axis=1)\n",
        "  train_scores_std = np.std(train_scores, axis=1)\n",
        "  test_scores_mean = np.mean(test_scores, axis=1)\n",
        "  test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "  axes.grid()\n",
        "  axes.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
        "                    train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                    color=\"r\")\n",
        "  axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                    test_scores_mean + test_scores_std, alpha=0.1, \n",
        "                    color=\"g\")\n",
        "  axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "            label=\"Training score\")\n",
        "  axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "            label=\"Cross-validation score\")\n",
        "  axes.legend(loc=\"best\")\n",
        "\n",
        "  return plt\n",
        "\n",
        "  \n",
        "\n",
        "# fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
        "\n",
        "# X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# title = r\"Learning Curves (SVM, linear kernel)\"\n",
        "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "# estimator = SVC(kernel='linear')\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves (SVM, rbf kernel)\"\n",
        "# cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "# estimator = SVC(gamma=0.001)\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves (SVM, poly kernel)\"\n",
        "# cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "# estimator = SVC(kernel='poly')\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 2], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves (SVM, sigmoid kernel)\"\n",
        "# cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "# estimator = SVC(kernel='sigmoid')\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 3], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves RF\"\n",
        "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "# estimator = RandomForestClassifier()\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 4], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, scoring='accuracy' n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves KNeighborsClassifier()\"\n",
        "# cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "# estimator = KNeighborsClassifier()\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
        "# # SVC is more expensive so we do a lower number of CV iterations:\n",
        "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "# estimator = SVC(gamma=0.001)\n",
        "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
        "#                     cv=cv, n_jobs=4)\n",
        "\n",
        "# plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCKzUBX7rpOj"
      },
      "source": [
        "## Run Pipeline\n",
        "\n",
        "run all predefined steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IYk4DjwcF48",
        "colab_type": "code",
        "outputId": "7365a64c-f756-4e7d-9eb5-156ead2d6e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Data loading functions.\n",
        "from brats.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "# split labels and values\n",
        "data_X = data.drop(columns=['label'])\n",
        "data_Y = data[['label']]\n",
        "\n",
        "# data split index forming\n",
        "Test_split = model_selection.StratifiedKFold(n_splits=10)\n",
        "results = list()\n",
        "best_parameters = list()\n",
        "results_outer = list()\n",
        "\n",
        "i = 0\n",
        "for design_index, test_index in Test_split.split(data_X, data_Y):\n",
        "    if i:\n",
        "      continue\n",
        "    X_design = data_X.iloc[design_index]\n",
        "    Y_design = data_Y.iloc[design_index]\n",
        "    \n",
        "    X_test = data_X.iloc[test_index]\n",
        "    Y_test = data_Y.iloc[test_index]\n",
        "\n",
        "    # run preprocessing step\n",
        "    X_design, Y_design, X_test, Y_test = preprocessing_steps(X_design, Y_design, X_test, Y_test)\n",
        "    print(X_design)\n",
        "    \n",
        "    #run feature selection and extraction\n",
        "    X_design, Y_design, Y_design_bin = feature_steps(X_design, Y_design)\n",
        "    i = 1\n",
        "    Y_test = Y_test.replace('LGG', 0)\n",
        "    Y_test = Y_test.replace('GBM', 1)\n",
        "    results, results_outer = classifiers (X_design, Y_design_bin, X_test, Y_test)\n",
        "  \n",
        "# Selecting best overall classifier   \n",
        "results_outer = pd.DataFrame(results_outer)\n",
        "print(results_outer)\n",
        "\n",
        "optimal_classifier = str(results_outer.median['clf_name'])\n",
        "print(f\"The optimal classifier={optimal_classifier}\")\n",
        "\n",
        "# save data to csv for manual check\n",
        "#X_design.to_csv('data_X.csv')\n",
        "#Y_design.to_csv('data_Y.csv')\n",
        "\n",
        "#Plotten learning curves\n",
        "num = 0\n",
        "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
        "for X, Y in zip (Xs, Ys):\n",
        "  ax = fig.add_subplot(7, 3, num+1)\n",
        "  ax.scatter(X[:,1], marker='o', c=Y,\n",
        "             s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "  num += 1\n",
        "\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_stage=0)\n",
        "\n",
        "for clf in clsfs:\n",
        "  for X, Y in zip(Xs, Ys):\n",
        "      title = str(type(clf))\n",
        "      ax = fig.add_subplot(7, 3, num+1)\n",
        "      plot_learning_curve(clf, title, X, Y, ax, ylim=(0.3, 1.01), cv=cv)\n",
        "      num += 1\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n",
            "              VOLUME_ET  VOLUME_NET  ...  TGM_Cog_Z_1   TGM_T_1\n",
            "ID                                   ...                       \n",
            "TCGA-02-0064   0.306650   -0.149335  ...    -0.409811  0.412749\n",
            "TCGA-02-0068  -0.131777   -0.098523  ...    -0.254765 -0.182429\n",
            "TCGA-02-0069  -0.006484    0.912666  ...     0.284368  2.705034\n",
            "TCGA-02-0070  -0.274249   -0.314443  ...     0.839935 -0.449039\n",
            "TCGA-02-0075  -0.109278    0.247846  ...     0.451606 -0.017942\n",
            "...                 ...         ...  ...          ...       ...\n",
            "TCGA-HT-8018  -0.506682   -0.179239  ...    -0.849962 -0.833459\n",
            "TCGA-HT-8111  -0.512206   -0.381408  ...     1.026131 -0.804997\n",
            "TCGA-HT-8114  -0.282298    3.740634  ...     0.526592 -0.757509\n",
            "TCGA-HT-8563  -0.181188   -0.367314  ...    -0.466627 -0.801878\n",
            "TCGA-HT-A61A   0.757504    1.082333  ...    -0.592295  0.330073\n",
            "\n",
            "[150 rows x 698 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best classifier: parameters={'kernel': 'rbf', 'degree': 2}\n",
            "{'mean_fit_time': array([0.00464363, 0.00370831, 0.00335326, 0.00355592, 0.00346618,\n",
            "       0.00380874, 0.00322533, 0.00388045, 0.00361414, 0.00474339]), 'std_fit_time': array([2.22345613e-04, 1.19154097e-04, 7.74247000e-05, 2.23086449e-04,\n",
            "       5.27506481e-05, 7.33793205e-04, 4.52179953e-04, 2.44987702e-04,\n",
            "       1.15468990e-04, 3.44146938e-04]), 'mean_score_time': array([0.00364022, 0.00341721, 0.0034286 , 0.00348835, 0.00343685,\n",
            "       0.0040132 , 0.00371451, 0.0035419 , 0.00358067, 0.00366783]), 'std_score_time': array([8.56733735e-05, 1.15196930e-04, 1.79407254e-04, 1.37239202e-04,\n",
            "       2.38446301e-04, 1.10161060e-03, 4.20571628e-04, 1.19244799e-04,\n",
            "       1.81216917e-04, 9.46109091e-05]), 'param_kernel': masked_array(data=['sigmoid', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
            "                   'poly', 'poly', 'rbf', 'sigmoid'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_degree': masked_array(data=[2, 2, 3, 1, 1, 4, 1, 4, 3, 4],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'kernel': 'sigmoid', 'degree': 2}, {'kernel': 'rbf', 'degree': 2}, {'kernel': 'linear', 'degree': 3}, {'kernel': 'rbf', 'degree': 1}, {'kernel': 'linear', 'degree': 1}, {'kernel': 'rbf', 'degree': 4}, {'kernel': 'poly', 'degree': 1}, {'kernel': 'poly', 'degree': 4}, {'kernel': 'rbf', 'degree': 3}, {'kernel': 'sigmoid', 'degree': 4}], 'split0_test_AUC': array([0.51674641, 0.66507177, 0.59808612, 0.66507177, 0.59808612,\n",
            "       0.66507177, 0.58373206, 0.5645933 , 0.66507177, 0.51674641]), 'split1_test_AUC': array([0.30555556, 0.85648148, 0.7037037 , 0.85648148, 0.7037037 ,\n",
            "       0.85648148, 0.73611111, 0.84722222, 0.85648148, 0.30555556]), 'split2_test_AUC': array([0.6712963 , 0.98148148, 0.84259259, 0.98148148, 0.84259259,\n",
            "       0.98148148, 0.84259259, 0.97685185, 0.98148148, 0.6712963 ]), 'split3_test_AUC': array([0.53703704, 0.93981481, 0.75      , 0.93981481, 0.75      ,\n",
            "       0.93981481, 0.74074074, 0.88425926, 0.93981481, 0.53703704]), 'split4_test_AUC': array([0.33333333, 0.77777778, 0.56944444, 0.77777778, 0.56944444,\n",
            "       0.77777778, 0.58333333, 0.65277778, 0.77777778, 0.33333333]), 'mean_test_AUC': array([0.47279373, 0.84412547, 0.69276537, 0.84412547, 0.69276537,\n",
            "       0.84412547, 0.69730197, 0.78514088, 0.84412547, 0.47279373]), 'std_test_AUC': array([0.13629389, 0.11369964, 0.10001586, 0.11369964, 0.10001586,\n",
            "       0.11369964, 0.10038866, 0.1527042 , 0.11369964, 0.13629389]), 'rank_test_AUC': array([9, 1, 7, 1, 7, 1, 6, 5, 1, 9], dtype=int32), 'split0_test_Accuracy': array([0.5       , 0.7       , 0.66666667, 0.7       , 0.66666667,\n",
            "       0.7       , 0.66666667, 0.73333333, 0.7       , 0.5       ]), 'split1_test_Accuracy': array([0.43333333, 0.73333333, 0.66666667, 0.73333333, 0.66666667,\n",
            "       0.73333333, 0.73333333, 0.7       , 0.73333333, 0.43333333]), 'split2_test_Accuracy': array([0.46666667, 0.96666667, 0.83333333, 0.96666667, 0.83333333,\n",
            "       0.96666667, 0.83333333, 0.76666667, 0.96666667, 0.46666667]), 'split3_test_Accuracy': array([0.4       , 0.9       , 0.76666667, 0.9       , 0.76666667,\n",
            "       0.9       , 0.76666667, 0.76666667, 0.9       , 0.4       ]), 'split4_test_Accuracy': array([0.4       , 0.7       , 0.53333333, 0.7       , 0.53333333,\n",
            "       0.7       , 0.6       , 0.66666667, 0.7       , 0.4       ]), 'mean_test_Accuracy': array([0.44      , 0.8       , 0.69333333, 0.8       , 0.69333333,\n",
            "       0.8       , 0.72      , 0.72666667, 0.8       , 0.44      ]), 'std_test_Accuracy': array([0.03887301, 0.11155467, 0.10198039, 0.11155467, 0.10198039,\n",
            "       0.11155467, 0.08055364, 0.03887301, 0.11155467, 0.03887301]), 'rank_test_Accuracy': array([9, 1, 7, 1, 7, 1, 6, 5, 1, 9], dtype=int32), 'split0_test_f1-score': array([0.59459459, 0.76923077, 0.75      , 0.76923077, 0.75      ,\n",
            "       0.76923077, 0.75      , 0.82608696, 0.76923077, 0.59459459]), 'split1_test_f1-score': array([0.58536585, 0.78947368, 0.70588235, 0.78947368, 0.70588235,\n",
            "       0.78947368, 0.77777778, 0.7804878 , 0.78947368, 0.58536585]), 'split2_test_f1-score': array([0.63636364, 0.97142857, 0.84848485, 0.97142857, 0.84848485,\n",
            "       0.97142857, 0.84848485, 0.8372093 , 0.97142857, 0.63636364]), 'split3_test_f1-score': array([0.55      , 0.91891892, 0.78787879, 0.91891892, 0.78787879,\n",
            "       0.91891892, 0.78787879, 0.8372093 , 0.91891892, 0.55      ]), 'split4_test_f1-score': array([0.4375    , 0.79069767, 0.65      , 0.79069767, 0.65      ,\n",
            "       0.79069767, 0.68421053, 0.7826087 , 0.79069767, 0.4375    ]), 'mean_test_f1-score': array([0.56076482, 0.84794992, 0.7484492 , 0.84794992, 0.7484492 ,\n",
            "       0.84794992, 0.76967039, 0.81272041, 0.84794992, 0.56076482]), 'std_test_f1-score': array([0.06749066, 0.08145867, 0.06792409, 0.08145867, 0.06792409,\n",
            "       0.08145867, 0.05347767, 0.02578268, 0.08145867, 0.06749066]), 'rank_test_f1-score': array([9, 1, 7, 1, 7, 1, 6, 5, 1, 9], dtype=int32)}\n",
            "0.8441254651780967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best classifier: parameters={'n_estimators': 86}\n",
            "{'mean_fit_time': array([0.37761168, 0.09973984, 0.04282904, 0.43702135, 0.43927255,\n",
            "       0.32295346, 0.42603564, 0.31878119, 0.37771153, 0.44681668]), 'std_fit_time': array([0.0051901 , 0.00256769, 0.00107914, 0.00633095, 0.00864319,\n",
            "       0.00798483, 0.0147036 , 0.00739416, 0.00450905, 0.00887749]), 'mean_score_time': array([0.04482923, 0.01563568, 0.00856705, 0.05254602, 0.05205879,\n",
            "       0.03976526, 0.05032425, 0.04055519, 0.04684005, 0.05259671]), 'std_score_time': array([0.00092858, 0.00126494, 0.00042236, 0.00156411, 0.0008485 ,\n",
            "       0.00259722, 0.00151085, 0.00249658, 0.00197161, 0.00038595]), 'param_n_estimators': masked_array(data=[326, 86, 36, 381, 386, 281, 371, 276, 336, 396],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'n_estimators': 326}, {'n_estimators': 86}, {'n_estimators': 36}, {'n_estimators': 381}, {'n_estimators': 386}, {'n_estimators': 281}, {'n_estimators': 371}, {'n_estimators': 276}, {'n_estimators': 336}, {'n_estimators': 396}], 'split0_test_AUC': array([0.72248804, 0.76076555, 0.76076555, 0.72248804, 0.71770335,\n",
            "       0.72248804, 0.73205742, 0.75598086, 0.715311  , 0.715311  ]), 'split1_test_AUC': array([0.77546296, 0.78009259, 0.75231481, 0.77314815, 0.77314815,\n",
            "       0.77546296, 0.77777778, 0.77546296, 0.78703704, 0.77314815]), 'split2_test_AUC': array([0.96296296, 0.96527778, 0.96990741, 0.96296296, 0.96759259,\n",
            "       0.96296296, 0.97222222, 0.98148148, 0.98148148, 0.96296296]), 'split3_test_AUC': array([0.88888889, 0.89814815, 0.88888889, 0.89351852, 0.88425926,\n",
            "       0.88657407, 0.88425926, 0.89351852, 0.88888889, 0.89351852]), 'split4_test_AUC': array([0.76157407, 0.77314815, 0.75      , 0.76388889, 0.75      ,\n",
            "       0.76851852, 0.74074074, 0.75462963, 0.75925926, 0.75462963]), 'mean_test_AUC': array([0.82227539, 0.83548644, 0.82437533, 0.82320131, 0.81854067,\n",
            "       0.82320131, 0.82141148, 0.83221469, 0.82639553, 0.81991405]), 'std_test_AUC': array([0.08951416, 0.08162112, 0.08956807, 0.09016016, 0.09323291,\n",
            "       0.08827429, 0.09283269, 0.09065377, 0.09628418, 0.0930285 ]), 'rank_test_AUC': array([ 7,  1,  4,  5, 10,  5,  8,  2,  3,  9], dtype=int32), 'split0_test_Accuracy': array([0.7       , 0.7       , 0.73333333, 0.73333333, 0.7       ,\n",
            "       0.73333333, 0.73333333, 0.73333333, 0.7       , 0.7       ]), 'split1_test_Accuracy': array([0.7       , 0.7       , 0.66666667, 0.7       , 0.7       ,\n",
            "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.7       ]), 'split2_test_Accuracy': array([0.93333333, 0.93333333, 0.86666667, 0.9       , 0.9       ,\n",
            "       0.93333333, 0.93333333, 0.93333333, 0.9       , 0.93333333]), 'split3_test_Accuracy': array([0.76666667, 0.76666667, 0.7       , 0.76666667, 0.76666667,\n",
            "       0.8       , 0.76666667, 0.8       , 0.8       , 0.8       ]), 'split4_test_Accuracy': array([0.73333333, 0.66666667, 0.7       , 0.66666667, 0.7       ,\n",
            "       0.7       , 0.7       , 0.73333333, 0.7       , 0.7       ]), 'mean_test_Accuracy': array([0.76666667, 0.75333333, 0.73333333, 0.75333333, 0.75333333,\n",
            "       0.76666667, 0.76      , 0.77333333, 0.75333333, 0.76666667]), 'std_test_Accuracy': array([0.0869227 , 0.09568467, 0.06992059, 0.08055364, 0.07774603,\n",
            "       0.0942809 , 0.09285592, 0.09043107, 0.08589399, 0.09189366]), 'rank_test_Accuracy': array([ 2,  8, 10,  8,  6,  2,  5,  1,  6,  2], dtype=int32), 'split0_test_f1-score': array([0.76923077, 0.76923077, 0.8       , 0.8       , 0.76923077,\n",
            "       0.8       , 0.78947368, 0.8       , 0.7804878 , 0.76923077]), 'split1_test_f1-score': array([0.72727273, 0.72727273, 0.70588235, 0.72727273, 0.72727273,\n",
            "       0.70588235, 0.70588235, 0.70588235, 0.70588235, 0.72727273]), 'split2_test_f1-score': array([0.94117647, 0.94117647, 0.88235294, 0.90909091, 0.90909091,\n",
            "       0.94117647, 0.94117647, 0.94117647, 0.90909091, 0.94117647]), 'split3_test_f1-score': array([0.8       , 0.8       , 0.72727273, 0.8       , 0.8       ,\n",
            "       0.83333333, 0.8       , 0.83333333, 0.83333333, 0.83333333]), 'split4_test_f1-score': array([0.78947368, 0.73684211, 0.75675676, 0.73684211, 0.75675676,\n",
            "       0.75675676, 0.75675676, 0.78947368, 0.75675676, 0.76923077]), 'mean_test_f1-score': array([0.80543073, 0.79490441, 0.77445296, 0.79464115, 0.79247023,\n",
            "       0.80742978, 0.79865785, 0.81397317, 0.79711023, 0.80804881]), 'std_test_f1-score': array([0.07229127, 0.07749309, 0.06250778, 0.06486203, 0.06280656,\n",
            "       0.07936499, 0.07843558, 0.07620314, 0.06939599, 0.07470038]), 'rank_test_f1-score': array([ 4,  7, 10,  8,  9,  3,  5,  1,  6,  2], dtype=int32)}\n",
            "0.8354864433811802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best classifier: parameters={'weights': 'uniform', 'n_neighbors': 9}\n",
            "{'mean_fit_time': array([0.00215092, 0.00220461, 0.00238218, 0.00211916, 0.00226922,\n",
            "       0.00220575, 0.00202756, 0.00206833, 0.00227156, 0.00202947]), 'std_fit_time': array([1.33907268e-04, 8.64966570e-05, 5.34491716e-04, 7.89240548e-05,\n",
            "       1.09021952e-04, 3.53247056e-04, 6.41180925e-05, 7.31366858e-05,\n",
            "       4.36833058e-04, 6.51437746e-05]), 'mean_score_time': array([0.00498028, 0.00485778, 0.00503049, 0.00424047, 0.00438051,\n",
            "       0.00553708, 0.00589724, 0.00557513, 0.00615206, 0.00578694]), 'std_score_time': array([7.41185654e-05, 1.22365000e-04, 7.30758065e-04, 1.30978965e-04,\n",
            "       2.26572045e-04, 3.83236353e-04, 2.01148283e-04, 5.94128563e-04,\n",
            "       7.65595501e-04, 1.63396614e-04]), 'param_weights': masked_array(data=['uniform', 'uniform', 'distance', 'distance',\n",
            "                   'distance', 'distance', 'uniform', 'distance',\n",
            "                   'uniform', 'uniform'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_n_neighbors': masked_array(data=[9, 1, 13, 3, 7, 87, 91, 75, 81, 93],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'weights': 'uniform', 'n_neighbors': 9}, {'weights': 'uniform', 'n_neighbors': 1}, {'weights': 'distance', 'n_neighbors': 13}, {'weights': 'distance', 'n_neighbors': 3}, {'weights': 'distance', 'n_neighbors': 7}, {'weights': 'distance', 'n_neighbors': 87}, {'weights': 'uniform', 'n_neighbors': 91}, {'weights': 'distance', 'n_neighbors': 75}, {'weights': 'uniform', 'n_neighbors': 81}, {'weights': 'uniform', 'n_neighbors': 93}], 'split0_test_AUC': array([0.78947368, 0.6937799 , 0.76315789, 0.6937799 , 0.76315789,\n",
            "       0.70334928, 0.63397129, 0.68899522, 0.61722488, 0.65311005]), 'split1_test_AUC': array([0.80555556, 0.65277778, 0.77777778, 0.7037037 , 0.76388889,\n",
            "       0.8287037 , 0.69212963, 0.8287037 , 0.79166667, 0.68981481]), 'split2_test_AUC': array([1.        , 0.79166667, 0.98148148, 0.94675926, 0.97685185,\n",
            "       0.94907407, 0.88425926, 0.94907407, 0.92361111, 0.81481481]), 'split3_test_AUC': array([0.92361111, 0.88888889, 0.9537037 , 0.97685185, 0.95833333,\n",
            "       0.94907407, 0.72222222, 0.93518519, 0.76851852, 0.69675926]), 'split4_test_AUC': array([0.8287037 , 0.68055556, 0.78703704, 0.76157407, 0.79166667,\n",
            "       0.71759259, 0.61111111, 0.72222222, 0.59490741, 0.60416667]), 'mean_test_AUC': array([0.86946881, 0.74153376, 0.85263158, 0.81653376, 0.85077973,\n",
            "       0.82955875, 0.7087387 , 0.82483608, 0.73918572, 0.69173312]), 'std_test_AUC': array([0.08014449, 0.08729632, 0.0945824 , 0.12122728, 0.09610818,\n",
            "       0.10680244, 0.09631868, 0.10640424, 0.12109341, 0.06976772]), 'rank_test_AUC': array([ 1,  7,  2,  6,  3,  4,  9,  5,  8, 10], dtype=int32), 'split0_test_Accuracy': array([0.8       , 0.73333333, 0.7       , 0.7       , 0.8       ,\n",
            "       0.73333333, 0.7       , 0.66666667, 0.6       , 0.7       ]), 'split1_test_Accuracy': array([0.73333333, 0.66666667, 0.66666667, 0.7       , 0.7       ,\n",
            "       0.73333333, 0.6       , 0.73333333, 0.53333333, 0.6       ]), 'split2_test_Accuracy': array([0.96666667, 0.76666667, 0.96666667, 0.86666667, 0.93333333,\n",
            "       0.96666667, 0.6       , 0.96666667, 0.63333333, 0.6       ]), 'split3_test_Accuracy': array([0.83333333, 0.9       , 0.83333333, 0.93333333, 0.9       ,\n",
            "       0.9       , 0.6       , 0.9       , 0.7       , 0.6       ]), 'split4_test_Accuracy': array([0.76666667, 0.7       , 0.7       , 0.73333333, 0.73333333,\n",
            "       0.7       , 0.6       , 0.7       , 0.6       , 0.6       ]), 'mean_test_Accuracy': array([0.82      , 0.75333333, 0.77333333, 0.78666667, 0.81333333,\n",
            "       0.80666667, 0.62      , 0.79333333, 0.61333333, 0.62      ]), 'std_test_Accuracy': array([0.08055364, 0.08055364, 0.11234866, 0.09568467, 0.09092121,\n",
            "       0.10624918, 0.04      , 0.11813363, 0.05416026, 0.04      ]), 'rank_test_Accuracy': array([ 1,  7,  6,  5,  2,  3,  8,  4, 10,  8], dtype=int32), 'split0_test_f1-score': array([0.84210526, 0.8       , 0.76923077, 0.76923077, 0.85      ,\n",
            "       0.8       , 0.80851064, 0.73684211, 0.68421053, 0.80851064]), 'split1_test_f1-score': array([0.77777778, 0.72222222, 0.70588235, 0.74285714, 0.74285714,\n",
            "       0.8       , 0.75      , 0.8       , 0.69565217, 0.75      ]), 'split2_test_f1-score': array([0.97142857, 0.77419355, 0.97142857, 0.875     , 0.94117647,\n",
            "       0.97142857, 0.75      , 0.97142857, 0.76595745, 0.75      ]), 'split3_test_f1-score': array([0.85714286, 0.91891892, 0.85714286, 0.94736842, 0.91891892,\n",
            "       0.91891892, 0.75      , 0.91891892, 0.75675676, 0.75      ]), 'split4_test_f1-score': array([0.8372093 , 0.75675676, 0.76923077, 0.78947368, 0.78947368,\n",
            "       0.79069767, 0.75      , 0.79069767, 0.68421053, 0.75      ]), 'mean_test_f1-score': array([0.85713275, 0.79441829, 0.81458306, 0.824786  , 0.84848524,\n",
            "       0.85620903, 0.76170213, 0.84357745, 0.71735749, 0.76170213]), 'std_test_f1-score': array([0.06321948, 0.06718819, 0.09202321, 0.07562219, 0.07509264,\n",
            "       0.07459051, 0.02340426, 0.087304  , 0.03628449, 0.02340426]), 'rank_test_f1-score': array([ 1,  7,  6,  5,  3,  2,  8,  4, 10,  8], dtype=int32)}\n",
            "0.8694688109161793\n",
            "Best classifier: parameters={}\n",
            "{'mean_fit_time': array([0.00226068]), 'std_fit_time': array([7.51666894e-05]), 'mean_score_time': array([0.00354805]), 'std_score_time': array([0.00014745]), 'params': [{}], 'split0_test_AUC': array([0.61244019]), 'split1_test_AUC': array([0.74074074]), 'split2_test_AUC': array([0.90740741]), 'split3_test_AUC': array([0.81481481]), 'split4_test_AUC': array([0.54166667]), 'mean_test_AUC': array([0.72341396]), 'std_test_AUC': array([0.13255578]), 'rank_test_AUC': array([1], dtype=int32), 'split0_test_Accuracy': array([0.66666667]), 'split1_test_Accuracy': array([0.7]), 'split2_test_Accuracy': array([0.83333333]), 'split3_test_Accuracy': array([0.7]), 'split4_test_Accuracy': array([0.5]), 'mean_test_Accuracy': array([0.68]), 'std_test_Accuracy': array([0.10666667]), 'rank_test_Accuracy': array([1], dtype=int32), 'split0_test_f1-score': array([0.76190476]), 'split1_test_f1-score': array([0.74285714]), 'split2_test_f1-score': array([0.85714286]), 'split3_test_f1-score': array([0.75675676]), 'split4_test_f1-score': array([0.61538462]), 'mean_test_f1-score': array([0.74680923]), 'std_test_f1-score': array([0.07718599]), 'rank_test_f1-score': array([1], dtype=int32)}\n",
            "0.7234139642034378\n",
            "   accuracy       AUC  ...                                parameters         set\n",
            "0  0.800000  0.844125  ...            {'kernel': 'rbf', 'degree': 2}  validation\n",
            "1  0.753333  0.835486  ...                      {'n_estimators': 86}  validation\n",
            "2  0.820000  0.869469  ...  {'weights': 'uniform', 'n_neighbors': 9}  validation\n",
            "3  0.680000  0.723414  ...                                        {}  validation\n",
            "\n",
            "[4 rows x 8 columns]\n",
            "index_best_classifier=mean_score    2\n",
            "dtype: int64\n",
            "best_classifier=[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
            "                     weights='uniform')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4140bb9f819b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LGG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GBM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_outer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_design\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_design_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Selecting best overall classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b4b41e280fa>\u001b[0m in \u001b[0;36mclassifiers\u001b[0;34m(X_design, Y_design, X_test, Y_test)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m    \u001b[0;31m#Test the classifier on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m    \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m    \u001b[0;31m#Gettin accuracy, AUC and f1-score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 delayed_query(\n\u001b[1;32m    663\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             )\n\u001b[1;32m    666\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: query data dimension must match training data dimension"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEHCAYAAACJN7BNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n17Hh/NoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}