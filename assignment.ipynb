{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fjoru/TM10007_PROJECT/blob/Carlijn/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Prediction of tumor grade in brain cancer\n",
        "By Jessica Barends, Gonnie van Erp, Erik Kemper en Carlijn Oerlemans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xw_qQnScF4p",
        "colab_type": "code",
        "outputId": "5ab74175-1418-4201-bb82-057a45b6ba27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run install for use in colab environment\n",
        "!pip install --upgrade pip\n",
        "!pip install -q --upgrade git+https://github.com/Fjoru/TM10007_PROJECT\n",
        "!pip install ipdb -q\n",
        "!pip install seaborn\n",
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 34.1MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 35.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 38.5MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 40.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 42.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 42.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 43.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 44.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 44.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 44.4MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 44.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 44.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 44.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 44.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 44.4MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 44.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 44.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 44.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 522kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 532kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 552kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 563kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 573kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 593kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 604kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 614kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 624kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 696kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 706kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 727kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 737kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 747kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 757kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 778kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 788kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 798kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 819kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 829kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 839kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 849kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 870kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 880kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 890kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 901kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 911kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 921kB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 931kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 952kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 962kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 972kB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 983kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 44.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 44.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (46.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF9cuHLcdguY",
        "colab_type": "text"
      },
      "source": [
        "## Import section\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pgvYp3dGOO",
        "colab_type": "code",
        "outputId": "175cace3-9acf-439d-f8f0-b04d6088ae82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import ipdb\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn import svm\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ-dUjXUpFAG",
        "colab_type": "text"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyRkeYMXnkN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Replace(i):\n",
        "    if isinstance(i, int):\n",
        "          return i\n",
        "    try:\n",
        "        float(i)\n",
        "        return float(i)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def preprocessing_steps(X_design, Y_design, X_test, Y_test):\n",
        "    # training set\n",
        "    # remove strings from data\n",
        "    X_design = X_design.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_design.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_design.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # remove features with less than 60% values\n",
        "    X_design = X_design.dropna(thresh=round(X_design.shape[0]*0.6), axis='columns')\n",
        "\n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_design = X_design.join(Y_design)\n",
        "    # remove samples with not enough values\n",
        "    XY_design = XY_design.dropna(thresh=round(XY_design.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_design['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_design = XY_design[XY_design['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_data) and labels (Y_data)\n",
        "    X_design = XY_design.drop(columns=['label'])\n",
        "    Y_design = XY_design[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    imputer = IterativeImputer(sample_posterior=True, n_nearest_features=20, random_state=0)\n",
        "    X_design_imputed = imputer.fit_transform(X_design)\n",
        "\n",
        "    # normalization of values\n",
        "    scaler = RobustScaler()\n",
        "    X_design_scaled = scaler.fit_transform(X_design_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_design = pd.DataFrame(X_design_scaled, columns=X_design.columns, index=X_design.index)\n",
        "\n",
        "    ####### test set\n",
        "    # remove strings from data\n",
        "    X_test = X_test.applymap(func=Replace)\n",
        "\n",
        "    # set 0.0 as NaN\n",
        "    X_test.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # set Inf as NaN\n",
        "    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    \n",
        "    # remove the same features as the design set\n",
        "    features_design = X_design.columns\n",
        "    features_design = X_design.columns\n",
        "    \n",
        "    df_test = None\n",
        "    for feature in features_design:\n",
        "      df_test_single = pd.DataFrame(X_test[feature])\n",
        "      if df_test is None:\n",
        "        df_test = df_test_single\n",
        "      else:\n",
        "        df_test = df_test.join(df_test_single, how='outer')\n",
        "    \n",
        "    X_test = df_test\n",
        "    \n",
        "    # remove sample with less than 60% values\n",
        "    # join features and labels\n",
        "    XY_test = X_test.join(Y_test)\n",
        "    # remove samples with not enough values\n",
        "    XY_test = XY_test.dropna(thresh=round(XY_test.shape[1]*0.6))\n",
        "\n",
        "    # remove samples without a label\n",
        "    XY_test['label'].replace(np.nan, '', inplace=True)\n",
        "    XY_test = XY_test[XY_test['label'].astype(bool)]\n",
        "\n",
        "    # split features (X_test) and labels (Y_test)\n",
        "    X_test = XY_test.drop(columns=['label'])\n",
        "    Y_test = XY_test[['label']]\n",
        "    \n",
        "    # add missing value's \n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    # normalization of values\n",
        "    X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "    # getting back to Dataframe \n",
        "    X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    return X_design, Y_design, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBXawKAVfGD",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection and extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8o6DTQGVvjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_steps(X_design, Y_design):\n",
        "\n",
        "    impo_clf = ExtraTreesClassifier(n_estimators=50)\n",
        "    impo_clf = impo_clf.fit(X_data, Y_data)\n",
        "    impo_clf.feature_importances_\n",
        "\n",
        "    importances = impo_clf.feature_importances_\n",
        "    std = np.std([impo_clf.feature_importances_ for tree in impo_clf.estimators_], \n",
        "                 axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature importances\")\n",
        "    plt.bar(range(X_data.shape[1]), importances[indices],\n",
        "            color=\"r\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(X_data.shape[1]), indices)\n",
        "    plt.xlim([-1, X_data.shape[1]])\n",
        "    plt.show()\n",
        "\n",
        "    model = SelectFromModel(impo_clf, prefit=True)\n",
        "    X_data = model.transform(X_data)\n",
        "\n",
        "    return X_data, Y_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HF4A2NuvEj8K"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaddUaf5Dwvo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgPqwhpaDwc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "h = .02\n",
        "names = [\"Decision Tree\", \"Random Forest\", \"Nearest Neighbors\", \"Linear SVM\"]\n",
        "\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(1.0 * RBF(1.0)),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025), \n",
        "    SVC(gamma=2, C=1)]\n",
        "\n",
        "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
        "                           random_state=1, n_clusters_per_class=1)\n",
        "rng = np.random.RandomState(2)\n",
        "X += 2 * rng.uniform(size=X.shape)\n",
        "linearly_separable = (X, y)\n",
        "\n",
        "datasets = [make_moons(noise=0.3, random_state=0),\n",
        "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
        "            linearly_separable\n",
        "            ]\n",
        "\n",
        "figure = plt.figure(figsize=(27, 9))\n",
        "i = 1\n",
        "\n",
        "# iterate over datasets\n",
        "for ds_cnt, ds in enumerate(datasets):\n",
        "    # preprocess dataset, split into training and test part\n",
        "    X, y = ds\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    X_design, X_test, y_design, y_test = \\\n",
        "        train_test_split(X, y, test_size=.4, random_state=42)\n",
        "\n",
        "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # just plot the dataset first\n",
        "    cm = plt.cm.RdBu\n",
        "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
        "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
        "    if ds_cnt == 0:\n",
        "        ax.set_title(\"Input data\")\n",
        "    # Plot the training points\n",
        "    ax.scatter(X_design[:, 0], X_design[:, 1], c=y_design, cmap=cm_bright,\n",
        "               edgecolors='k')\n",
        "    # Plot the testing points\n",
        "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
        "               edgecolors='k')\n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    i += 1\n",
        "\n",
        "        # iterate over classifiers\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
        "        clf.fit(X_design, y_design)\n",
        "        score = clf.score(X_test, y_test)\n",
        "\n",
        "        # Plot the decision boundary. For that, we will assign a color to each\n",
        "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "        if hasattr(clf, \"decision_function\"):\n",
        "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "        else:\n",
        "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "\n",
        "        # Put the result into a color plot\n",
        "        Z = Z.reshape(xx.shape)\n",
        "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "\n",
        "        # Plot the training points\n",
        "        ax.scatter(X_design[:, 0], X_design[:, 1], c=y_design, cmap=cm_bright,\n",
        "                   edgecolors='k')\n",
        "        # Plot the testing points\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
        "                   edgecolors='k', alpha=0.6)\n",
        "\n",
        "        ax.set_xlim(xx.min(), xx.max())\n",
        "        ax.set_ylim(yy.min(), yy.max())\n",
        "        ax.set_xticks(())\n",
        "        ax.set_yticks(())\n",
        "        if ds_cnt == 0:\n",
        "            ax.set_title(name)\n",
        "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
        "                size=15, horizontalalignment='right')\n",
        "        i += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Osv2atFjIASr"
      },
      "source": [
        "## Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IYk4DjwcF48",
        "colab_type": "code",
        "outputId": "6f1a41ee-71f0-405e-f3be-2d6409ed6b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# Data loading functions.\n",
        "from brats.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "# split labels and values\n",
        "data_X = data.drop(columns=['label'])\n",
        "data_Y = data[['label']]\n",
        "\n",
        "# data split index forming\n",
        "Test_split = model_selection.StratifiedKFold(n_splits=10)\n",
        "results = list()\n",
        "best_kernel = list()\n",
        "\n",
        "i = 0\n",
        "for design_index, test_index in Test_split.split(data_X, data_Y):\n",
        "    if i:\n",
        "      continue\n",
        "    X_design = data_X.iloc[design_index]\n",
        "    Y_design = data_Y.iloc[design_index]\n",
        "    \n",
        "    X_test = data_X.iloc[test_index]\n",
        "    Y_test = data_Y.iloc[test_index]\n",
        "\n",
        "    # run preprocessing step\n",
        "    X_design, Y_design, X_test, Y_test = preprocessing_steps(X_design, Y_design, X_test, Y_test)\n",
        "    print(X_design)\n",
        "    \n",
        "    #run feature selection and extraction\n",
        "    X_design, Y_design = feature_steps(X_design, Y_design)\n",
        "\n",
        "    i = 1\n",
        "    \n",
        "    ## Example for Classifier hyperparameters selecting\n",
        "    clf = svm.SVC(probability=True)\n",
        "    parameters = parameters = {\n",
        "        \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']}\n",
        "    random_search = model_selection.RandomizedSearchCV(clf, parameters, scoring='roc_auc') ## hierin zit al de crossvalidatie, dus opnieuw een k-fold split hoeft niet #keuze om score voor alle classifiers gelijk te houden of per classifier te definieren\n",
        "    random_search.fit(X_design, Y_design)\n",
        "\n",
        "    # Get resulting classifier\n",
        "    clf_best = random_search.best_estimator_\n",
        "    print(f'Best classifier: kernel={clf_best.kernel}')\n",
        "    best_kernel.append(clf_best.kernel)   #per fold best classifier will be appended\n",
        "\n",
        "    # Test the classifier on the test data\n",
        "    prob = clf_best.predict_proba(X_test)\n",
        "    scores = prob[:, 1]\n",
        "\n",
        "    # Gettin accuracy, AUC and f1-score\n",
        "    accuracy = metrics.accuracy_score(Y_test, scores)\n",
        "    auc = metrics.roc_auc_score(Y_test, scores)\n",
        "    f1 = metrics.f1_score(Y_test, scores)\n",
        "    results.append({\n",
        "        'accuracy': accuracy,\n",
        "        'AUC': auc,\n",
        "        'f1-score': f1,\n",
        "        'kernel': clf_best.kernel,\n",
        "        'set': test\n",
        "    })\n",
        "\n",
        "    # Test the classifier on the training data\n",
        "    prob_testing = clf.predict_proba(X_design)\n",
        "    scores_training = probab_testing[:, 1]\n",
        "    \n",
        "    # Getting the accuracy, AUC and f1-score\n",
        "    accuracy = metrics.accuracy_score(Y_design, scores_training)\n",
        "    auc = metrics.roc_auc_score(Y_design, scores_training)\n",
        "    f1 = metrics.f1_score(Y_design, scores_training)\n",
        "    results.append({\n",
        "        'accuracy': accuracy,\n",
        "        'AUC': auc,\n",
        "        'f1-score': f1,\n",
        "        'kernel': clf_best.kernel,\n",
        "        'set': training\n",
        "    })\n",
        "\n",
        "    # Create results dataframe and plot it\n",
        "    results = pd.DataFrame(results)\n",
        "    seaborn.boxplot(y='AUC', x='set', data=results)\n",
        "    seaborn.boxplot(y='accuracy', x='set', data=results)\n",
        "    seaborn.boxplot(y='f1-score', x='set', data=results)\n",
        "\n",
        "    optimal_kernel = int(np.median(best_kernel))\n",
        "    print(f\"The optimal kernel={optimal_kernel}\")\n",
        "\n",
        "# save data to csv for manual check\n",
        "#X_design.to_csv('data_X.csv')\n",
        "#Y_design.to_csv('data_Y.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n",
            "              VOLUME_ET  VOLUME_NET  ...  TGM_Cog_Z_1   TGM_T_1\n",
            "ID                                   ...                       \n",
            "TCGA-02-0064   0.306650   -0.149335  ...    -0.409811  0.412749\n",
            "TCGA-02-0068  -0.131777   -0.098523  ...    -0.254765 -0.182429\n",
            "TCGA-02-0069  -0.006484    0.912666  ...     0.284368  2.705034\n",
            "TCGA-02-0070  -0.274249   -0.314443  ...     0.839935 -0.449039\n",
            "TCGA-02-0075  -0.109278    0.247846  ...     0.451606 -0.017942\n",
            "...                 ...         ...  ...          ...       ...\n",
            "TCGA-HT-8018  -0.506682   -0.179239  ...    -0.849962 -0.833459\n",
            "TCGA-HT-8111  -0.512206   -0.381408  ...     1.026131 -0.804997\n",
            "TCGA-HT-8114  -0.282298    3.740634  ...     0.526592 -0.757509\n",
            "TCGA-HT-8563  -0.181188   -0.367314  ...    -0.466627 -0.801878\n",
            "TCGA-HT-A61A   0.757504    1.082333  ...    -0.592295  0.330073\n",
            "\n",
            "[150 rows x 698 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ba4302003181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#run feature selection and extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mX_design\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_design\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_design\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_design\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-10de2a540e07>\u001b[0m in \u001b[0;36mfeature_steps\u001b[0;34m(X_design, Y_design)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimpo_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimpo_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpo_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimpo_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'X_data' referenced before assignment"
          ]
        }
      ]
    }
  ]
}